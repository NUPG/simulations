{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pprint import pprint\n",
    "from peer_review import *\n",
    "from vancouver_simulations import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vancouver Iterations\n",
    "\n",
    "Upon working more with the code and moving it into my IDE, I discovered that I had neglected to pass the number of iterations to Vancouver appropriately. I have corrected that error, but per the below it doesn't look like it makes much of a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.randint, 1, 5), num_trials=40, use_cover=True, vancouver_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.randint, 1, 5), num_trials=40, use_cover=True, vancouver_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.randint, 1, 5), num_trials=40, use_cover=True, vancouver_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.randint, 1, 5), num_trials=40, use_cover=True, vancouver_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like over a uniform distribution of graders, even a single iteration of Vancouver is pretty much the same as multiple iterations of it. My next step will be to examine other distributions.\n",
    "\n",
    "## Attempt to Elicit Non-Linear Decrease in Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_histogram(peer_quality=(random.randint, 1, 5), num_truths=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_histogram(peer_quality=(random.randint, 1, 5), num_truths=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.choice, [1, 5]), num_trials=40, use_cover=True, vancouver_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution at Extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_histogram(peer_quality=(random.choice, [1, 5]), num_truths=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_histogram(peer_quality=(random.choice, [1, 5]), num_truths=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.choice, [1, 5]), num_trials=40, use_cover=True, vancouver_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.choice, [1, 10]), num_trials=40, use_cover=True, vancouver_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewed Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.choice, [1, 5, 5, 5]), num_trials=40, use_cover=True, vancouver_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.choice, [1, 5, 5, 5]), num_trials=100, use_cover=True, vancouver_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.choice, [1, 10, 10, 10]), num_trials=20, use_cover=True, vancouver_steps=10,\n",
    "          num_subs=50, num_grades_per_sub=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_stats('mean', 'sub_grade', (random.choice, [1, 1, 1, 5]), num_trials=20, use_cover=True, vancouver_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are linear for all three of these distributions. The fluctuations in quality with no ground truth are probably due to the differences in grader quality, with distributions that have more high-quality graders ending up with better grades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to Find Better Algorithms for Order of Ground-Truth Grades\n",
    "I will start this examination by finding out if grading in the order of most error or most variance, or a multiple of the two, has any effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alg(t, init, actual):\n",
    "    scores = init[0]\n",
    "    qualities = init[1]\n",
    "    omni_scores = actual[0]\n",
    "    true_qualities = actual[1]\n",
    "    \n",
    "    sub_score_error = [abs(scores[submission][0] - 0.5) for submission in scores]\n",
    "    sub_var_error = [abs(scores[submission][1] - omni_scores[submission][1]) for submission in scores]\n",
    "    grader_var_error = [abs(qualities[grader] - true_qualities[grader]) for grader in qualities]\n",
    "    \n",
    "    return max(sub_grade_error.iteritems(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "plot_histogram(peer_quality=(random.choice, [1, 5]), num_truths=15, grading_algorithm=alg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_histogram(peer_quality=(random.choice, [1, 5]), num_truths=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def alg2(t, init, actual):\n",
    "    scores = init[0]\n",
    "    qualities = init[1]\n",
    "    omni_scores = actual[0]\n",
    "    true_qualities = actual[1]\n",
    "    \n",
    "    sub_score_error = [abs(scores[submission][0] - 0.5) for submission in scores]\n",
    "    sub_var_error = [abs(scores[submission][1] - omni_scores[submission][1]) for submission in scores]\n",
    "    grader_var_error = [abs(qualities[grader] - true_qualities[grader]) for grader in qualities]\n",
    "    \n",
    "    sub_var = [scores[submission][1] for submission in scores]\n",
    "    \n",
    "    return max(sub_var.iteritems(), key=operator.itemgetter(1))[0]\n",
    "\n",
    "plot_histogram(peer_quality=(random.choice, [1, 5]), num_truths=15, grading_algorithm=alg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing by highest grade error and choosing by highest variance appear to have minimal effects compared to choosing randomly after the cover. I have run these trials at a couple different num_truths values, and it looks like all three methods are pretty even."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
