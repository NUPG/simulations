{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from peer_review_assignments import *\n",
    "import numpy as np\n",
    "\n",
    "# generates random reviews for assignments \n",
    "#    (assignments as returned from peer_assignments())\n",
    "#   qualities: {i => number of draws from distribituion}\n",
    "def random_reviews(assignments, qualities = {}):\n",
    "    # fill in qualities if empty.\n",
    "    # default quality is 1.\n",
    "    if len(qualities.keys()) < 1:\n",
    "        qs = {i: 1 for i in assignments.keys()}\n",
    "        qs.update(qualities)\n",
    "        qualities = qs;\n",
    "        \n",
    "    # Uniform reviews\n",
    "    #reviews = {i: {j: np.mean([random.random() for _ in range(qualities[i])]) for j in js} for (i, js) in assignments.items()} \n",
    "    \n",
    "    # Binomial reviews\n",
    "    reviews = {i : {j: np.random.binomial(qualities[i],0.5)/qualities[i] for j in js} for (i,js) in assignments.items()}\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "MIN_VARIANCE = 0.001  # don't let 1/variance blow up if a peer is very accurate.\n",
    "DEFAULT_VARIANCE = 1.0  # this does not matter as long as it is the same.\n",
    "\n",
    "\n",
    "# assign students in groups to k submissions.\n",
    "#    reviews:     {'peer name' => {'submission name' => score} \n",
    "#    truth:       {'submission name'=> score}\n",
    "#    t:           number of iterations after which to quit.\n",
    "# returns:\n",
    "#    (scores,qualities): ({submission=>(score,var)},{peer=>var})\n",
    "def simple_vancouver(reviews, truth, t):\n",
    "    # i: peers; j: submissions\n",
    "\n",
    "    # strip scores \n",
    "    #   iassign[i] = submissions assigned to peer i\n",
    "    #   jassign[j] = peers assigned to review submission j\n",
    "    iassign = {i: review.keys() for (i, review) in reviews.items()}\n",
    "    jassign = invert_dictlist_dup(iassign)\n",
    "\n",
    "    peers = iassign.keys()\n",
    "    submissions = jassign.keys()\n",
    "\n",
    "    # ivar[i] and jvar[j] are 1/variance\n",
    "    jvar = {j: 1.0 / DEFAULT_VARIANCE for j in submissions}\n",
    "    jmean = {j: 0.0 for j in submissions}\n",
    "    ivar = {i: 1.0 / DEFAULT_VARIANCE for i in peers}\n",
    "\n",
    "    for _ in range(t):\n",
    "        # update score ivariances: jvar[j] = sum_i ivar[i]\n",
    "        #    notes: ignores old ivar\n",
    "        jvar = {j: sum([ivar[i] for i in jassign[j]]) for j in submissions}\n",
    "\n",
    "        # update score mean: jmean[j] = (sum_i reviews[i,j] ivar[i]) / jvar[j]] \n",
    "        jmean = {j: sum([reviews[i][j] * ivar[i] for i in jassign[j]]) / jvar[j] for j in submissions}\n",
    "\n",
    "        # reset the truth.\n",
    "        jmean.update(truth)\n",
    "\n",
    "        # update qualities: ivar[i] = (sum_j jvar[j]) / (sum_j jvar[j](reviews[i][j]-jmean[j]))\n",
    "        ivar = {i: min(1 / MIN_VARIANCE,\n",
    "                       sum([jvar[j] for j in iassign[i]]) / \\\n",
    "                       sum([jvar[j] * (reviews[i][j] - jmean[j]) ** 2 for j in iassign[i]])) \\\n",
    "                for i in peers}\n",
    "\n",
    "    scores = {j: (jmean[j], 1.0 / jvar[j]) for j in submissions}\n",
    "    quality = {i: 1.0 / ivar[i] for i in peers}\n",
    "\n",
    "    return (scores, quality)\n",
    "\n",
    "\n",
    "# assign students in groups to k submissions.\n",
    "#    reviews:     {'peer name' => {'submission name' => score} \n",
    "#    truth:       {'submission name'=> score}\n",
    "#    t:           number of iterations after which to quit.\n",
    "# returns:\n",
    "#    (scores,qualities): ({submission=>(score,var)},{peer=>var})\n",
    "# PRECONDITIONS:\n",
    "#    - peers assigned to at least two submissions.\n",
    "#    - submissions assigned to at least two peers.\n",
    "# NOTES:\n",
    "#    - runs exactly t iterations.  does not stop if no improvements.\n",
    "def vancouver(reviews, truth, t):\n",
    "    # i: peers; j: submissions\n",
    "\n",
    "    # strip scores \n",
    "    #   iassign[i] = submissions assigned to peer i\n",
    "    #   jassign[j] = peers assigned to review submission j\n",
    "    iassign = {i: review.keys() for (i, review) in reviews.items()}\n",
    "    jassign = invert_dictlist_dup(iassign)\n",
    "\n",
    "    # make sure preconditions are met\n",
    "    kmin = min(len(subs) for (i, subs) in iassign.items())\n",
    "    assert kmin >= 2, \"Vancouver needs at least two submissions per peer!\"\n",
    "    lmin = min(len(peers) for (j, peers) in jassign.items())\n",
    "    assert lmin >= 2, \"Vancouver needs at least two peers per submission!\"\n",
    "\n",
    "    peers = iassign.keys()\n",
    "    submissions = jassign.keys()\n",
    "\n",
    "    # maintain ivar, jvar, jmean for each edge in assignment\n",
    "    # ivar and jvar are 1/variance!\n",
    "    ivars = {i: {j: 1.0 / DEFAULT_VARIANCE for j in iassign[i]} for i in peers}\n",
    "    jvars = {i: {j: 1.0 / DEFAULT_VARIANCE for j in iassign[i]} for i in peers}\n",
    "    # jmean = {i: {j: avg([reviews[ii][j] for ii in jassign[j] if ii != i]) for j in iassign[i]} for i in peers}\n",
    "    jmeans = {i: {j: 1.0 for j in iassign[i]} for i in peers}\n",
    "\n",
    "    for _ in range(t):\n",
    "        # update score inverse variances for submissions\n",
    "        jvars = {i: {j: sum([ivars[ii][j] for ii in jassign[j] if ii != i]) for j in iassign[i]} for i in peers}\n",
    "\n",
    "        # update score mean: jmean[j] = (sum_i reviews[i,j] ivar[i]) / jvar[j]] \n",
    "        jmeans = {i: {j: truth[j] if j in truth \\\n",
    "            else sum([reviews[ii][j] * ivars[ii][j] for ii in jassign[j] if ii != i]) / jvars[i][j] \\\n",
    "                      for j in iassign[i]} \\\n",
    "                  for i in peers}\n",
    "\n",
    "        # update qualities: ivar[i] = (sum_j jvar[j]) / (sum_j jvar[j](reviews[i][j]-jmean[j]))\n",
    "        ivars = {i: {j: min(1 / MIN_VARIANCE,\n",
    "                            sum([jvars[i][jj] for jj in iassign[i] if jj != j]) / \\\n",
    "                            sum([jvars[i][jj] * (reviews[i][jj] - jmeans[i][jj]) ** 2 for jj in iassign[i] if jj != j])) \\\n",
    "                     for j in iassign[i]}\n",
    "                 for i in peers}\n",
    "\n",
    "    # update score ivariances: jvar[j] = sum_i ivar[i]\n",
    "    #    notes: ignores old ivar\n",
    "    jvar = {j: sum([ivars[i][j] for i in jassign[j]]) for j in submissions}\n",
    "\n",
    "    # update score mean: jmean[j] = (sum_i reviews[i,j] ivar[i]) / jvar[j]] \n",
    "    jmean = {j: sum([reviews[i][j] * ivars[i][j] for i in jassign[j]]) / jvar[j] for j in submissions}\n",
    "\n",
    "    # reset the truth.\n",
    "    jmean.update(truth)\n",
    "\n",
    "    # update qualities: ivar[i] = (sum_j jvar[j]) / (sum_j jvar[j](reviews[i][j]-jmean[j]))\n",
    "    ivar = {i: min(1 / MIN_VARIANCE,\n",
    "                   sum([jvars[i][j] for j in iassign[i]]) / \\\n",
    "                   sum([jvars[i][j] * (reviews[i][j] - jmeans[i][j]) ** 2 for j in iassign[i]])) \\\n",
    "            for i in peers}\n",
    "\n",
    "    scores = {j: (jmean[j], 1.0 / jvar[j]) for j in submissions}\n",
    "    quality = {i: 1.0 / ivar[i] for i in peers}\n",
    "\n",
    "    return (scores, quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# generate groups\n",
    "\n",
    "L = [chr(ord('a') + z) for z in range(26)];\n",
    "bigL = [x + y for x in L for y in L]\n",
    "bigGroups = {sub : [sub + x for x in ['1','2','3']] for sub in bigL[:90]};\n",
    "\n",
    "# relevant info for these groups\n",
    "submissions = bigGroups.keys()\n",
    "exclude = invert_dictlist(bigGroups)\n",
    "students = exclude.keys()\n",
    "\n",
    "\n",
    "# initialize some variables\n",
    "submissionVariances = [];\n",
    "studentQualities = [];\n",
    "\n",
    "number_of_trials = 1;\n",
    "number_of_steps = 15;\n",
    "k = 3;\n",
    "\n",
    "for _ in range(number_of_trials):\n",
    "\n",
    "    # generate assignments\n",
    "    emptycover = {s: [] for s in students}\n",
    "    assignments = peer_assignment_with_cover(bigGroups,k,emptycover)\n",
    "\n",
    "    # ground truth\n",
    "    trueGrades = {j:0.5 for j in submissions}\n",
    "    trueQualities = {i: random.getrandbits(1)*4+1 for i in students}\n",
    "\n",
    "    # generate some grades\n",
    "    reviews = random_reviews(assignments,trueQualities)\n",
    "    (grades,qualities) = vancouver(reviews,trueGrades,number_of_steps);\n",
    "    #(grades,qualities) = simple_vancouver(reviews,trueGrades,number_of_steps);\n",
    "\n",
    "    # (true, estimate) pairs\n",
    "    submissionVariances += [(1.0/12,grades[sub][1]) for sub in submissions]\n",
    "    studentQualities += [(trueQualities[i],qualities[i]) for i in students]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot student quality estimates\n",
    "x = [v[0] for v in studentQualities]\n",
    "y = [v[1] for v in studentQualities]\n",
    "plt.scatter(x,y)\n",
    "plt.xlabel('Student qualities')\n",
    "plt.ylabel('Estimated student variances')\n",
    "plt.title('Estimated Student Variances vs Qualities')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot submission variance histogram\n",
    "# should be centered at 1/12\n",
    "x = [v[1] for v in submissionVariances]\n",
    "plt.hist(x)\n",
    "plt.xlabel('Submission Variances')\n",
    "plt.title('Submission Variance Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
